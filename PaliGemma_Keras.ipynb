{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Captioning with PaliGemma: Step-by-Step Code Walkthrough**\n"
      ],
      "metadata": {
        "id": "8og3e33nSrwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Required Libraries:\n",
        "First, we need to install the necessary libraries to access the PaliGemma model. Specifically, we’ll use the keras-nlp library:"
      ],
      "metadata": {
        "id": "oiQeNu6kS3ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the following Keras required libraries\n",
        "!pip install -q --upgrade keras-nlp\n",
        "!pip install -q --upgrade keras>=3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLCC3_-Oj5wx",
        "outputId": "7b612de9-016e-4383-8b5b-9d4ad7f0f3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.2/572.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries:\n",
        "Next, we import the libraries that will be used throughout the code:"
      ],
      "metadata": {
        "id": "i8JEE0OsS_w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import keras_nlp\n",
        "from IPython.display import Markdown\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DFxLPpISj52n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up Kaggle Credentials:\n",
        "Here, I retrieve the Kaggle credentials from the environment. Make sure to store your Kaggle username and API key in the Colab secret keys for secure access"
      ],
      "metadata": {
        "id": "U4WXYsg1TJ_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve Kaggle credentials from the environment\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
      ],
      "metadata": {
        "id": "KQvGsq29j56V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the PaliGemma Model:\n",
        "Now, we load the PaliGemma model. I’m using the pali_gemma_3b_mix_448 preset, which is a pre-trained checkpoint optimized for images with a resolution of 448x448 pixels:"
      ],
      "metadata": {
        "id": "HU8PWEGxTS4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load paligemma from a preset\n",
        "pali_gemma_lm = keras_nlp.models.PaliGemmaCausalLM.from_preset(\"pali_gemma_3b_mix_448\")"
      ],
      "metadata": {
        "id": "NMR6xMlbkSER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Model Summary:\n",
        "We can now display a summary of the loaded model to understand its structure and parameters:"
      ],
      "metadata": {
        "id": "Y2RFpZp0TXfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pali_gemma_lm.summary()"
      ],
      "metadata": {
        "id": "n623egfcN9U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Prepare the Image:\n",
        "To process an image, we first load it using Keras’s load_img function, which also allows resizing to the required dimensions. Then, we convert the image to a NumPy array."
      ],
      "metadata": {
        "id": "Zmf824VOTpt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Image to Tensor:\n",
        "Next, we transform the NumPy array into a Tensor object using TensorFlow’s convert_to_tensor function, making it ready for the PaliGemma model."
      ],
      "metadata": {
        "id": "aEP3P44BTuCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_URL_HERE = 'https://storage.googleapis.com/keras-cv/models/paligemma/cow_beach_1.png'\n",
        "image_path = tf.keras.utils.get_file('image_filename.jpg', IMAGE_URL_HERE)\n",
        "keras_img = load_img(image_path, target_size=(448,448))\n",
        "img_array = img_to_array(keras_img)\n",
        "img_tensor = tf.convert_to_tensor(img_array)"
      ],
      "metadata": {
        "id": "gJEI2g-UkR74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the Image\n",
        "Before passing the image to PaliGemma, let's display it to see what we're working with. Here’s the image we’ll use (for example, a cow):"
      ],
      "metadata": {
        "id": "wgn8FhhdT64o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# img_tensor = tf.expand_dims(img_array.astype('float32') / 255.0, axis=0)  # Normalize values between 0 and 1\n",
        "# Display the image using matplotlib\n",
        "# plt.imshow(img_tensor[0])  # Access the first image from the batch dimension\n",
        "plt.imshow(keras_img[0])\n",
        "plt.axis('off')  # Hide the axes for a cleaner image display\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DjuaztpiOpty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate an Image Caption\n",
        "Now, we use PaliGemma to generate a caption. Start by defining a prompt, such as \"Caption the image in detail.\" Then, pass both the image and the prompt to the generate() function:"
      ],
      "metadata": {
        "id": "FYLKvevQT_FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define prompt separately so we can measure its length later\n",
        "prompt = \"Caption the image:\"\n",
        "# pass images and prompts to  paligemma\n",
        "response = pali_gemma_lm.generate( { \"images\": [img_tensor], \"prompts\": [prompt] } )\n",
        "# we're not using an instruction-trained model so we have to cut the prompt off\n",
        "# the front of our output\n",
        "filtered = response[0][len(prompt):]\n",
        "print(filtered)"
      ],
      "metadata": {
        "id": "57la789RlOgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}